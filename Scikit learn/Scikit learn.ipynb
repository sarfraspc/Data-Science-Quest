{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scikit learn\n",
    "\n",
    "### Modeling by Scikit-Learn\n",
    "\n",
    "-   Regression Models\n",
    "\n",
    "    \\## **1Ô∏è‚É£ Linear Regression (California Housing Dataset)**\n",
    "\n",
    "    üí° **Used for Predicting House Prices**\n",
    "\n",
    "    ``` python\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "    from sklearn.datasets import fetch_california_housing\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "    # Load dataset\n",
    "    data = fetch_california_housing(as_frame=True)\n",
    "    df = data.frame\n",
    "\n",
    "    # Define features and target\n",
    "    X = df.drop(columns=[\"MedHouseVal\"])\n",
    "    y = df[\"MedHouseVal\"]\n",
    "\n",
    "    # Train-test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Standardize features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # Train Linear Regression model\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "\n",
    "    # Predictions\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "    # Evaluation\n",
    "    print(\"üìä Linear Regression Model Evaluation:\")\n",
    "    print(\"MAE:\", mean_absolute_error(y_test, y_pred))\n",
    "    print(\"MSE:\", mean_squared_error(y_test, y_pred))\n",
    "    print(\"RMSE:\", np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "    print(\"R¬≤ Score:\", r2_score(y_test, y_pred))\n",
    "    ```\n",
    "\n",
    "    üí° **Used self data**\n",
    "\n",
    "    ``` python\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "    # Synthetic dataset (fixed indentation)\n",
    "    X_reg = np.array([[1], [2], [3], [4], [5]])\n",
    "    y_reg = np.array([1, 3, 2, 3, 5])\n",
    "\n",
    "    # Split data\n",
    "    X_train_r, X_test_r, y_train_r, y_test_r = train_test_split(X_reg, y_reg, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Train model\n",
    "    reg_model = LinearRegression()\n",
    "    reg_model.fit(X_train_r, y_train_r)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred_r = reg_model.predict(X_test_r)\n",
    "    print(\"Linear Regression Predictions:\", y_pred_r)\n",
    "\n",
    "    # Evaluate model\n",
    "    mse = mean_squared_error(y_test_r, y_pred_r)\n",
    "    r2 = r2_score(y_test_r, y_pred_r)\n",
    "    print(f\"Mean Squared Error: {mse}\")\n",
    "    print(f\"R^2 Score: {r2}\")\n",
    "    ```\n",
    "\n",
    "    \\### **Decision Tree Regression for California Housing**\n",
    "\n",
    "    ``` python\n",
    "    python\n",
    "    CopyEdit\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.tree import DecisionTreeRegressor\n",
    "    from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "    from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "    # üì• Load dataset\n",
    "    data = fetch_california_housing(as_frame=True)\n",
    "    df = data.frame\n",
    "\n",
    "    # üéØ Define features and target\n",
    "    X = df.drop(columns=[\"MedHouseVal\"])\n",
    "    y = df[\"MedHouseVal\"]\n",
    "\n",
    "    # üîÄ Train-test split (80% train, 20% test)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # üå≥ Train Decision Tree Regression Model\n",
    "    model = DecisionTreeRegressor(max_depth=5, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # üìà Make Predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # üìä Model Evaluation\n",
    "    print(\"üìä Decision Tree Regression Model Evaluation:\")\n",
    "    print(\"MAE:\", mean_absolute_error(y_test, y_pred))\n",
    "    print(\"MSE:\", mean_squared_error(y_test, y_pred))\n",
    "    print(\"RMSE:\", np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "    print(\"R¬≤ Score:\", r2_score(y_test, y_pred))\n",
    "    ```\n",
    "\n",
    "    \\### **Decision Tree Regression with self data**\n",
    "\n",
    "    ``` python\n",
    "    python\n",
    "    CopyEdit\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.tree import DecisionTreeRegressor\n",
    "    from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "    # üìå Synthetic dataset (Fixed indentation)\n",
    "    X_reg = np.array([[1], [2], [3], [4], [5]])  # Feature\n",
    "    y_reg = np.array([1, 3, 2, 3, 5])  # Target\n",
    "\n",
    "    # üîÄ Split data (80% train, 20% test)\n",
    "    X_train_r, X_test_r, y_train_r, y_test_r = train_test_split(X_reg, y_reg, test_size=0.2, random_state=42)\n",
    "\n",
    "    # üå≥ Train Decision Tree Regression Model\n",
    "    tree_model = DecisionTreeRegressor(max_depth=3, random_state=42)\n",
    "    tree_model.fit(X_train_r, y_train_r)\n",
    "\n",
    "    # üìà Make Predictions\n",
    "    y_pred_r = tree_model.predict(X_test_r)\n",
    "    print(\"Decision Tree Predictions:\", y_pred_r)\n",
    "\n",
    "    # üìä Evaluate model\n",
    "    mse = mean_squared_error(y_test_r, y_pred_r)\n",
    "    r2 = r2_score(y_test_r, y_pred_r)\n",
    "    print(f\"Mean Squared Error: {mse}\")\n",
    "    print(f\"R^2 Score: {r2}\")\n",
    "\n",
    "    # üìä Plot Decision Tree Predictions\n",
    "    X_range = np.linspace(min(X_reg), max(X_reg), 100).reshape(-1, 1)\n",
    "    y_range_pred = tree_model.predict(X_range)\n",
    "\n",
    "    plt.scatter(X_reg, y_reg, color=\"blue\", label=\"Actual Data\")\n",
    "    plt.plot(X_range, y_range_pred, color=\"red\", linestyle=\"dashed\", label=\"Decision Tree Prediction\")\n",
    "    plt.xlabel(\"Feature (X)\")\n",
    "    plt.ylabel(\"Target (y)\")\n",
    "    plt.title(\"Decision Tree Regression\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    ```\n",
    "\n",
    "-   Classification\n",
    "\n",
    "    \\### **Logistic Regression Classifier**\n",
    "\n",
    "    ``` python\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.metrics import (\n",
    "        accuracy_score, confusion_matrix, classification_report, roc_curve, auc\n",
    "    )\n",
    "\n",
    "    # 1Ô∏è‚É£ Load Dataset (Iris Dataset - Binary Classification)\n",
    "    from sklearn.datasets import load_iris\n",
    "    iris = load_iris()\n",
    "    df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "    df['target'] = (iris.target == 0).astype(int)  # Convert to Binary (Setosa vs Non-Setosa)\n",
    "\n",
    "    # 2Ô∏è‚É£ Split Data into Train & Test\n",
    "    X = df.drop(columns=['target'])\n",
    "    y = df['target']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # 3Ô∏è‚É£ Standardization (Very Important for Logistic Regression!)\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # 4Ô∏è‚É£ Train Logistic Regression Model\n",
    "    model = LogisticRegression()\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "\n",
    "    # 5Ô∏è‚É£ Make Predictions\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    y_prob = model.predict_proba(X_test_scaled)[:, 1]  # Probability of class 1\n",
    "\n",
    "    # 6Ô∏è‚É£ Model Evaluation\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"‚úÖ Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    plt.figure(figsize=(5, 4))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"Non-Setosa\", \"Setosa\"], yticklabels=[\"Non-Setosa\", \"Setosa\"])\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.show()\n",
    "\n",
    "    # Classification Report\n",
    "    print(\"\\nüìå Classification Report:\\n\", classification_report(y_test, y_pred, target_names=[\"Non-Setosa\", \"Setosa\"]))\n",
    "\n",
    "    # 7Ô∏è‚É£ ROC Curve\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.plot(fpr, tpr, color='blue', label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(\"ROC Curve\")\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "    ```\n",
    "\n",
    "    \\## **Decision Tree Classifier (Titanic)**\n",
    "\n",
    "    ``` python\n",
    "    python\n",
    "    CopyEdit\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import seaborn as sns\n",
    "    import matplotlib.pyplot as plt\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "    # üì• Load Titanic Dataset from Seaborn\n",
    "    df = sns.load_dataset('titanic')\n",
    "\n",
    "    # üîç Select Important Features\n",
    "    df = df[['survived', 'pclass', 'sex', 'age', 'sibsp', 'parch', 'fare']]\n",
    "\n",
    "    # üõ†Ô∏è Handle Missing Values\n",
    "    df['age'].fillna(df['age'].median(), inplace=True)\n",
    "\n",
    "    # üîÑ Convert Categorical to Numeric (Sex: Male=1, Female=0)\n",
    "    df['sex'] = LabelEncoder().fit_transform(df['sex'])\n",
    "\n",
    "    # üéØ Define Features (X) and Target (y)\n",
    "    X = df.drop(columns=['survived'])\n",
    "    y = df['survived']\n",
    "\n",
    "    # üîÄ Train-Test Split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # üå≥ Train Decision Tree Classifier\n",
    "    dt_model = DecisionTreeClassifier(max_depth=5, random_state=42)\n",
    "    dt_model.fit(X_train, y_train)\n",
    "\n",
    "    # üìà Make Predictions\n",
    "    y_pred = dt_model.predict(X_test)\n",
    "\n",
    "    # üìä Model Evaluation\n",
    "    print(\"üìä Decision Tree Model Evaluation:\")\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "    print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "    # üìâ Confusion Matrix\n",
    "    sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.title(\"Confusion Matrix - Decision Tree\")\n",
    "    plt.show()\n",
    "    ```\n",
    "\n",
    "    \\### **üå≤ Random Forest Classifier**\n",
    "\n",
    "    ``` python\n",
    "    python\n",
    "    CopyEdit\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import seaborn as sns\n",
    "    import matplotlib.pyplot as plt\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "    # üì• Load Titanic Dataset from Seaborn\n",
    "    df = sns.load_dataset('titanic')\n",
    "\n",
    "    # üîç Select Important Features\n",
    "    df = df[['survived', 'pclass', 'sex', 'age', 'sibsp', 'parch', 'fare']]\n",
    "\n",
    "    # üõ†Ô∏è Handle Missing Values\n",
    "    df['age'].fillna(df['age'].median(), inplace=True)\n",
    "\n",
    "    # üîÑ Convert Categorical to Numeric (Sex: Male=1, Female=0)\n",
    "    df['sex'] = LabelEncoder().fit_transform(df['sex'])\n",
    "\n",
    "    # üéØ Define Features (X) and Target (y)\n",
    "    X = df.drop(columns=['survived'])\n",
    "    y = df['survived']\n",
    "\n",
    "    # üîÄ Train-Test Split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # üå≤ Train Random Forest Classifier\n",
    "    rf_model = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=42)\n",
    "    rf_model.fit(X_train, y_train)\n",
    "\n",
    "    # üìà Make Predictions\n",
    "    y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "    # üìä Model Evaluation\n",
    "    print(\"üìä Random Forest Model Evaluation:\")\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
    "    print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_rf))\n",
    "\n",
    "    # üìâ Confusion Matrix\n",
    "    sns.heatmap(confusion_matrix(y_test, y_pred_rf), annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.title(\"Confusion Matrix - Random Forest\")\n",
    "    plt.show()\n",
    "    ```\n",
    "\n",
    "-   clustering\n",
    "\n",
    "    \\### **K-Means Clustering with Evaluation**\n",
    "\n",
    "    ``` python\n",
    "    python\n",
    "    CopyEdit\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import seaborn as sns\n",
    "    import matplotlib.pyplot as plt\n",
    "    from sklearn.cluster import KMeans\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    from sklearn.metrics import silhouette_score, davies_bouldin_score\n",
    "    from sklearn.datasets import load_iris\n",
    "\n",
    "    # üì• Load Iris Dataset\n",
    "    iris = load_iris()\n",
    "    df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "\n",
    "    # üîç Standardize Data (K-Means is sensitive to scale)\n",
    "    scaler = StandardScaler()\n",
    "    df_scaled = scaler.fit_transform(df)\n",
    "\n",
    "    # üîÄ Train K-Means Model (Choosing 3 clusters since Iris has 3 species)\n",
    "    kmeans = KMeans(n_clusters=3, random_state=42, n_init=10)\n",
    "    df['Cluster'] = kmeans.fit_predict(df_scaled)\n",
    "\n",
    "    # üìà Evaluation Metrics\n",
    "    inertia = kmeans.inertia_  # WCSS\n",
    "    silhouette = silhouette_score(df_scaled, df['Cluster'])\n",
    "    davies_bouldin = davies_bouldin_score(df_scaled, df['Cluster'])\n",
    "\n",
    "    print(\"üìä K-Means Clustering Evaluation Metrics:\")\n",
    "    print(f\"üîπ Inertia (WCSS): {inertia:.2f}\")\n",
    "    print(f\"üîπ Silhouette Score: {silhouette:.4f} (Closer to 1 is better)\")\n",
    "    print(f\"üîπ Davies-Bouldin Score: {davies_bouldin:.4f} (Lower is better)\")\n",
    "\n",
    "    # üìä Visualizing Clusters\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.scatterplot(x=df.iloc[:, 0], y=df.iloc[:, 1], hue=df['Cluster'], palette='viridis')\n",
    "    plt.title(\"K-Means Clustering on Iris Dataset\")\n",
    "    plt.xlabel(iris.feature_names[0])\n",
    "    plt.ylabel(iris.feature_names[1])\n",
    "    plt.legend(title=\"Cluster\")\n",
    "    plt.show()\n",
    "    ```"
   ],
   "id": "42a14256-91c8-446e-92a7-ab6bf11055d3"
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {}
}
