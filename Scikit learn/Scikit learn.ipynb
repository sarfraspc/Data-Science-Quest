{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scikit learn\n",
    "\n",
    "### Modeling by Scikit-Learn\n",
    "\n",
    "-   Regression Models\n",
    "\n",
    "    \\## **1ï¸âƒ£ Linear Regression (California Housing Dataset)**\n",
    "\n",
    "    ğŸ’¡ **Used for Predicting House Prices**\n",
    "\n",
    "    ``` python\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "    from sklearn.datasets import fetch_california_housing\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "    # Load dataset\n",
    "    data = fetch_california_housing(as_frame=True)\n",
    "    df = data.frame\n",
    "\n",
    "    # Define features and target\n",
    "    X = df.drop(columns=[\"MedHouseVal\"])\n",
    "    y = df[\"MedHouseVal\"]\n",
    "\n",
    "    # Train-test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Standardize features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # Train Linear Regression model\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "\n",
    "    # Predictions\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "    # Evaluation\n",
    "    print(\"ğŸ“Š Linear Regression Model Evaluation:\")\n",
    "    print(\"MAE:\", mean_absolute_error(y_test, y_pred))\n",
    "    print(\"MSE:\", mean_squared_error(y_test, y_pred))\n",
    "    print(\"RMSE:\", np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "    print(\"RÂ² Score:\", r2_score(y_test, y_pred))\n",
    "    ```\n",
    "\n",
    "    ğŸ’¡ **Used self data**\n",
    "\n",
    "    ``` python\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "    # Synthetic dataset (fixed indentation)\n",
    "    X_reg = np.array([[1], [2], [3], [4], [5]])\n",
    "    y_reg = np.array([1, 3, 2, 3, 5])\n",
    "\n",
    "    # Split data\n",
    "    X_train_r, X_test_r, y_train_r, y_test_r = train_test_split(X_reg, y_reg, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Train model\n",
    "    reg_model = LinearRegression()\n",
    "    reg_model.fit(X_train_r, y_train_r)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred_r = reg_model.predict(X_test_r)\n",
    "    print(\"Linear Regression Predictions:\", y_pred_r)\n",
    "\n",
    "    # Evaluate model\n",
    "    mse = mean_squared_error(y_test_r, y_pred_r)\n",
    "    r2 = r2_score(y_test_r, y_pred_r)\n",
    "    print(f\"Mean Squared Error: {mse}\")\n",
    "    print(f\"R^2 Score: {r2}\")\n",
    "    ```\n",
    "\n",
    "    \\### **Decision Tree Regression for California Housing**\n",
    "\n",
    "    ``` python\n",
    "    python\n",
    "    CopyEdit\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.tree import DecisionTreeRegressor\n",
    "    from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "    from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "    # ğŸ“¥ Load dataset\n",
    "    data = fetch_california_housing(as_frame=True)\n",
    "    df = data.frame\n",
    "\n",
    "    # ğŸ¯ Define features and target\n",
    "    X = df.drop(columns=[\"MedHouseVal\"])\n",
    "    y = df[\"MedHouseVal\"]\n",
    "\n",
    "    # ğŸ”€ Train-test split (80% train, 20% test)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # ğŸŒ³ Train Decision Tree Regression Model\n",
    "    model = DecisionTreeRegressor(max_depth=5, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # ğŸ“ˆ Make Predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # ğŸ“Š Model Evaluation\n",
    "    print(\"ğŸ“Š Decision Tree Regression Model Evaluation:\")\n",
    "    print(\"MAE:\", mean_absolute_error(y_test, y_pred))\n",
    "    print(\"MSE:\", mean_squared_error(y_test, y_pred))\n",
    "    print(\"RMSE:\", np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "    print(\"RÂ² Score:\", r2_score(y_test, y_pred))\n",
    "    ```\n",
    "\n",
    "    \\### **Decision Tree Regression with self data**\n",
    "\n",
    "    ``` python\n",
    "    python\n",
    "    CopyEdit\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.tree import DecisionTreeRegressor\n",
    "    from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "    # ğŸ“Œ Synthetic dataset (Fixed indentation)\n",
    "    X_reg = np.array([[1], [2], [3], [4], [5]])  # Feature\n",
    "    y_reg = np.array([1, 3, 2, 3, 5])  # Target\n",
    "\n",
    "    # ğŸ”€ Split data (80% train, 20% test)\n",
    "    X_train_r, X_test_r, y_train_r, y_test_r = train_test_split(X_reg, y_reg, test_size=0.2, random_state=42)\n",
    "\n",
    "    # ğŸŒ³ Train Decision Tree Regression Model\n",
    "    tree_model = DecisionTreeRegressor(max_depth=3, random_state=42)\n",
    "    tree_model.fit(X_train_r, y_train_r)\n",
    "\n",
    "    # ğŸ“ˆ Make Predictions\n",
    "    y_pred_r = tree_model.predict(X_test_r)\n",
    "    print(\"Decision Tree Predictions:\", y_pred_r)\n",
    "\n",
    "    # ğŸ“Š Evaluate model\n",
    "    mse = mean_squared_error(y_test_r, y_pred_r)\n",
    "    r2 = r2_score(y_test_r, y_pred_r)\n",
    "    print(f\"Mean Squared Error: {mse}\")\n",
    "    print(f\"R^2 Score: {r2}\")\n",
    "\n",
    "    # ğŸ“Š Plot Decision Tree Predictions\n",
    "    X_range = np.linspace(min(X_reg), max(X_reg), 100).reshape(-1, 1)\n",
    "    y_range_pred = tree_model.predict(X_range)\n",
    "\n",
    "    plt.scatter(X_reg, y_reg, color=\"blue\", label=\"Actual Data\")\n",
    "    plt.plot(X_range, y_range_pred, color=\"red\", linestyle=\"dashed\", label=\"Decision Tree Prediction\")\n",
    "    plt.xlabel(\"Feature (X)\")\n",
    "    plt.ylabel(\"Target (y)\")\n",
    "    plt.title(\"Decision Tree Regression\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    ```\n",
    "\n",
    "-   Classification\n",
    "\n",
    "    \\### **Logistic Regression Classifier**\n",
    "\n",
    "    ``` python\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.metrics import (\n",
    "        accuracy_score, confusion_matrix, classification_report, roc_curve, auc\n",
    "    )\n",
    "\n",
    "    # 1ï¸âƒ£ Load Dataset (Iris Dataset - Binary Classification)\n",
    "    from sklearn.datasets import load_iris\n",
    "    iris = load_iris()\n",
    "    df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "    df['target'] = (iris.target == 0).astype(int)  # Convert to Binary (Setosa vs Non-Setosa)\n",
    "\n",
    "    # 2ï¸âƒ£ Split Data into Train & Test\n",
    "    X = df.drop(columns=['target'])\n",
    "    y = df['target']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # 3ï¸âƒ£ Standardization (Very Important for Logistic Regression!)\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # 4ï¸âƒ£ Train Logistic Regression Model\n",
    "    model = LogisticRegression()\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "\n",
    "    # 5ï¸âƒ£ Make Predictions\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    y_prob = model.predict_proba(X_test_scaled)[:, 1]  # Probability of class 1\n",
    "\n",
    "    # 6ï¸âƒ£ Model Evaluation\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"âœ… Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    plt.figure(figsize=(5, 4))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"Non-Setosa\", \"Setosa\"], yticklabels=[\"Non-Setosa\", \"Setosa\"])\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.show()\n",
    "\n",
    "    # Classification Report\n",
    "    print(\"\\nğŸ“Œ Classification Report:\\n\", classification_report(y_test, y_pred, target_names=[\"Non-Setosa\", \"Setosa\"]))\n",
    "\n",
    "    # 7ï¸âƒ£ ROC Curve\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.plot(fpr, tpr, color='blue', label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(\"ROC Curve\")\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "    ```\n",
    "\n",
    "    \\## **Decision Tree Classifier (Titanic)**\n",
    "\n",
    "    ``` python\n",
    "    python\n",
    "    CopyEdit\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import seaborn as sns\n",
    "    import matplotlib.pyplot as plt\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "    # ğŸ“¥ Load Titanic Dataset from Seaborn\n",
    "    df = sns.load_dataset('titanic')\n",
    "\n",
    "    # ğŸ” Select Important Features\n",
    "    df = df[['survived', 'pclass', 'sex', 'age', 'sibsp', 'parch', 'fare']]\n",
    "\n",
    "    # ğŸ› ï¸ Handle Missing Values\n",
    "    df['age'].fillna(df['age'].median(), inplace=True)\n",
    "\n",
    "    # ğŸ”„ Convert Categorical to Numeric (Sex: Male=1, Female=0)\n",
    "    df['sex'] = LabelEncoder().fit_transform(df['sex'])\n",
    "\n",
    "    # ğŸ¯ Define Features (X) and Target (y)\n",
    "    X = df.drop(columns=['survived'])\n",
    "    y = df['survived']\n",
    "\n",
    "    # ğŸ”€ Train-Test Split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # ğŸŒ³ Train Decision Tree Classifier\n",
    "    dt_model = DecisionTreeClassifier(max_depth=5, random_state=42)\n",
    "    dt_model.fit(X_train, y_train)\n",
    "\n",
    "    # ğŸ“ˆ Make Predictions\n",
    "    y_pred = dt_model.predict(X_test)\n",
    "\n",
    "    # ğŸ“Š Model Evaluation\n",
    "    print(\"ğŸ“Š Decision Tree Model Evaluation:\")\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "    print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "    # ğŸ“‰ Confusion Matrix\n",
    "    sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.title(\"Confusion Matrix - Decision Tree\")\n",
    "    plt.show()\n",
    "    ```\n",
    "\n",
    "    \\### **ğŸŒ² Random Forest Classifier**\n",
    "\n",
    "    ``` python\n",
    "    python\n",
    "    CopyEdit\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import seaborn as sns\n",
    "    import matplotlib.pyplot as plt\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "    # ğŸ“¥ Load Titanic Dataset from Seaborn\n",
    "    df = sns.load_dataset('titanic')\n",
    "\n",
    "    # ğŸ” Select Important Features\n",
    "    df = df[['survived', 'pclass', 'sex', 'age', 'sibsp', 'parch', 'fare']]\n",
    "\n",
    "    # ğŸ› ï¸ Handle Missing Values\n",
    "    df['age'].fillna(df['age'].median(), inplace=True)\n",
    "\n",
    "    # ğŸ”„ Convert Categorical to Numeric (Sex: Male=1, Female=0)\n",
    "    df['sex'] = LabelEncoder().fit_transform(df['sex'])\n",
    "\n",
    "    # ğŸ¯ Define Features (X) and Target (y)\n",
    "    X = df.drop(columns=['survived'])\n",
    "    y = df['survived']\n",
    "\n",
    "    # ğŸ”€ Train-Test Split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # ğŸŒ² Train Random Forest Classifier\n",
    "    rf_model = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=42)\n",
    "    rf_model.fit(X_train, y_train)\n",
    "\n",
    "    # ğŸ“ˆ Make Predictions\n",
    "    y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "    # ğŸ“Š Model Evaluation\n",
    "    print(\"ğŸ“Š Random Forest Model Evaluation:\")\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
    "    print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_rf))\n",
    "\n",
    "    # ğŸ“‰ Confusion Matrix\n",
    "    sns.heatmap(confusion_matrix(y_test, y_pred_rf), annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.title(\"Confusion Matrix - Random Forest\")\n",
    "    plt.show()\n",
    "    ```\n",
    "\n",
    "-   clustering\n",
    "\n",
    "    \\### **K-Means Clustering with Evaluation**\n",
    "\n",
    "    ``` python\n",
    "    python\n",
    "    CopyEdit\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import seaborn as sns\n",
    "    import matplotlib.pyplot as plt\n",
    "    from sklearn.cluster import KMeans\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    from sklearn.metrics import silhouette_score, davies_bouldin_score\n",
    "    from sklearn.datasets import load_iris\n",
    "\n",
    "    # ğŸ“¥ Load Iris Dataset\n",
    "    iris = load_iris()\n",
    "    df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "\n",
    "    # ğŸ” Standardize Data (K-Means is sensitive to scale)\n",
    "    scaler = StandardScaler()\n",
    "    df_scaled = scaler.fit_transform(df)\n",
    "\n",
    "    # ğŸ”€ Train K-Means Model (Choosing 3 clusters since Iris has 3 species)\n",
    "    kmeans = KMeans(n_clusters=3, random_state=42, n_init=10)\n",
    "    df['Cluster'] = kmeans.fit_predict(df_scaled)\n",
    "\n",
    "    # ğŸ“ˆ Evaluation Metrics\n",
    "    inertia = kmeans.inertia_  # WCSS\n",
    "    silhouette = silhouette_score(df_scaled, df['Cluster'])\n",
    "    davies_bouldin = davies_bouldin_score(df_scaled, df['Cluster'])\n",
    "\n",
    "    print(\"ğŸ“Š K-Means Clustering Evaluation Metrics:\")\n",
    "    print(f\"ğŸ”¹ Inertia (WCSS): {inertia:.2f}\")\n",
    "    print(f\"ğŸ”¹ Silhouette Score: {silhouette:.4f} (Closer to 1 is better)\")\n",
    "    print(f\"ğŸ”¹ Davies-Bouldin Score: {davies_bouldin:.4f} (Lower is better)\")\n",
    "\n",
    "    # ğŸ“Š Visualizing Clusters\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.scatterplot(x=df.iloc[:, 0], y=df.iloc[:, 1], hue=df['Cluster'], palette='viridis')\n",
    "    plt.title(\"K-Means Clustering on Iris Dataset\")\n",
    "    plt.xlabel(iris.feature_names[0])\n",
    "    plt.ylabel(iris.feature_names[1])\n",
    "    plt.legend(title=\"Cluster\")\n",
    "    plt.show()\n",
    "    ```"
   ],
   "id": "42a14256-91c8-446e-92a7-ab6bf11055d3"
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {}
}
