{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "\n",
    "**Preprocessing Techniques**\n",
    "\n",
    "### ðŸ”¹ Missing Value Handling\n",
    "\n",
    "### 1. **Drop Rows/Columns**\n",
    "\n",
    "-   **Drop rows** with missing values:\n",
    "\n",
    "    ``` python\n",
    "    python\n",
    "    CopyEdit\n",
    "    df.dropna(axis=0, inplace=True)\n",
    "    ```\n",
    "\n",
    "-   **Drop columns** with missing values:\n",
    "\n",
    "    ``` python\n",
    "    python\n",
    "    CopyEdit\n",
    "    df.dropna(axis=1, inplace=True)\n",
    "    ```\n",
    "\n",
    "### 2. **Fill with Mean/Median/Mode**\n",
    "\n",
    "-   **Mean**:\n",
    "\n",
    "    ``` python\n",
    "    python\n",
    "    CopyEdit\n",
    "    df['age'].fillna(df['age'].mean(), inplace=True)\n",
    "    ```\n",
    "\n",
    "-   **Median**:\n",
    "\n",
    "    ``` python\n",
    "    python\n",
    "    CopyEdit\n",
    "    df['income'].fillna(df['income'].median(), inplace=True)\n",
    "    ```\n",
    "\n",
    "-   **Mode**:\n",
    "\n",
    "    ``` python\n",
    "    python\n",
    "    CopyEdit\n",
    "    df['gender'].fillna(df['gender'].mode()[0], inplace=True)\n",
    "    ```\n",
    "\n",
    "### 3. **Forward/Backward Fill**\n",
    "\n",
    "-   **Forward Fill**: Fill missing values with the **last available\n",
    "    value** (i.e., carry forward the previous observation).\n",
    "\n",
    "    ``` python\n",
    "    python\n",
    "    CopyEdit\n",
    "    df.fillna(method='ffill', inplace=True)\n",
    "    ```\n",
    "\n",
    "-   **Backward Fill**: Fill missing values with the **next available\n",
    "    value** (i.e., fill using the value coming after the missing one).\n",
    "\n",
    "    ``` python\n",
    "    python\n",
    "    CopyEdit\n",
    "    df.fillna(method='bfill', inplace=True)\n",
    "    ```\n",
    "\n",
    "### 4. **KNN or Model-Based Imputation**\n",
    "\n",
    "-   **KNN Imputation**: This method uses **K-Nearest Neighbors (KNN)**\n",
    "    to impute missing values by looking at the **similarity** of other\n",
    "    data points. KNN identifies the closest rows (neighbors) and\n",
    "    predicts the missing value based on them.\n",
    "\n",
    "    ``` python\n",
    "    python\n",
    "    CopyEdit\n",
    "    from sklearn.impute import KNNImputer\n",
    "    imputer = KNNImputer(n_neighbors=5)\n",
    "    df_imputed = imputer.fit_transform(df)\n",
    "    ```\n",
    "\n",
    "-   **Model-Based Imputation**: You can use models (like **Random\n",
    "    Forests** or **Linear Regression**) to predict missing values by\n",
    "    training on the non-missing values and predicting for the missing\n",
    "    ones.\n",
    "\n",
    "    -   Example (using RandomForestRegressor for imputation):\n",
    "\n",
    "        ``` python\n",
    "        python\n",
    "        CopyEdit\n",
    "        from sklearn.ensemble import RandomForestRegressor\n",
    "        model = RandomForestRegressor()\n",
    "        df_missing = df[df['target'].isnull()]\n",
    "        df_not_missing = df[df['target'].notnull()]\n",
    "        model.fit(df_not_missing.drop('target', axis=1), df_not_missing['target'])\n",
    "        df_missing['target'] = model.predict(df_missing.drop('target', axis=1))\n",
    "        ```\n",
    "\n",
    "### ðŸ”¹ Categorical Encoding\n",
    "\n",
    "### 1. **Label Encoding**\n",
    "\n",
    "``` python\n",
    "python\n",
    "CopyEdit\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "df['size_encoded'] = le.fit_transform(df['size'])\n",
    "```\n",
    "\n",
    "### 2. **One-Hot Encoding**\n",
    "\n",
    "``` python\n",
    "python\n",
    "CopyEdit\n",
    "pd.get_dummies(df['color'], prefix='color')\n",
    "```\n",
    "\n",
    "### 3. **Target Encoding**\n",
    "\n",
    "-   **How** (with `category_encoders`):\n",
    "\n",
    "``` python\n",
    "python\n",
    "CopyEdit\n",
    "import category_encoders as ce\n",
    "encoder = ce.TargetEncoder()\n",
    "df['gender_encoded'] = encoder.fit_transform(df['gender'], df['target'])\n",
    "```\n",
    "\n",
    "### 4. **Frequency Encoding**\n",
    "\n",
    "``` python\n",
    "python\n",
    "CopyEdit\n",
    "freq_map = df['city'].value_counts().to_dict()\n",
    "df['city_encoded'] = df['city'].map(freq_map)\n",
    "```\n",
    "\n",
    "### ðŸ”¹ Feature Scaling / Normalization\n",
    "\n",
    "### 1. **StandardScaler (Z-score Normalization)**\n",
    "\n",
    "``` python\n",
    "python\n",
    "CopyEdit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "df_scaled = scaler.fit_transform(df)\n",
    "```\n",
    "\n",
    "### 2. **MinMaxScaler (Normalization to \\[0, 1\\])**\n",
    "\n",
    "``` python\n",
    "python\n",
    "CopyEdit\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "df_scaled = scaler.fit_transform(df)\n",
    "```\n",
    "\n",
    "### 3. **RobustScaler (Outlier-resistant)**\n",
    "\n",
    "``` python\n",
    "python\n",
    "CopyEdit\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "scaler = RobustScaler()\n",
    "df_scaled = scaler.fit_transform(df)\n",
    "```\n",
    "\n",
    "### 4. **PowerTransformer (Box-Cox / Yeo-Johnson)**\n",
    "\n",
    "``` python\n",
    "python\n",
    "CopyEdit\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "pt = PowerTransformer(method='yeo-johnson')  # or 'box-cox' if all values > 0\n",
    "df_transformed = pt.fit_transform(df)\n",
    "```\n",
    "\n",
    "### ðŸ”¹ Outlier Treatment\n",
    "\n",
    "### 1. **Z-score Method**\n",
    "\n",
    "``` python\n",
    "python\n",
    "CopyEdit\n",
    "from scipy.stats import zscore\n",
    "z = zscore(df['feature'])\n",
    "df[z > 3]  # outliers\n",
    "```\n",
    "\n",
    "### 2. **IQR Method (Interquartile Range)**\n",
    "\n",
    "``` python\n",
    "python\n",
    "CopyEdit\n",
    "Q1 = df['feature'].quantile(0.25)\n",
    "Q3 = df['feature'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "mask = (df['feature'] < Q1 - 1.5*IQR) | (df['feature'] > Q3 + 1.5*IQR)\n",
    "df[mask]  # outliers\n",
    "```\n",
    "\n",
    "### 3. **Winsorization / Clipping / Capping**\n",
    "\n",
    "-   **Winsorization** (clip at percentile):\n",
    "\n",
    "    ``` python\n",
    "    python\n",
    "    CopyEdit\n",
    "    from scipy.stats.mstats import winsorize\n",
    "    df['feature_wins'] = winsorize(df['feature'], limits=[0.05, 0.05])\n",
    "    ```\n",
    "\n",
    "-   **Clipping** (hard limit):\n",
    "\n",
    "    ``` python\n",
    "    python\n",
    "    CopyEdit\n",
    "    df['feature'] = df['feature'].clip(lower=lower_bound, upper=upper_bound)\n",
    "    ```\n",
    "\n",
    "### ðŸ”¹ Text Cleaning\n",
    "\n",
    "### 1. **Lowercase + Remove Punctuation**\n",
    "\n",
    "``` python\n",
    "python\n",
    "CopyEdit\n",
    "import string\n",
    "\n",
    "text = text.lower()  # lowercase\n",
    "text = text.translate(str.maketrans('', '', string.punctuation))  # remove punctuation\n",
    "```\n",
    "\n",
    "### 2. **Remove Stopwords**\n",
    "\n",
    "``` python\n",
    "python\n",
    "CopyEdit\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "words = [word for word in text.split() if word not in stop_words]\n",
    "```\n",
    "\n",
    "``` python\n",
    "python\n",
    "CopyEdit\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "```\n",
    "\n",
    "### 3. **Stemming / Lemmatization**\n",
    "\n",
    "### **Stemming**\n",
    "\n",
    "``` python\n",
    "python\n",
    "CopyEdit\n",
    "from nltk.stem import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "stemmed_words = [stemmer.stem(word) for word in words]\n",
    "```\n",
    "\n",
    "### **Lemmatization**\n",
    "\n",
    "``` python\n",
    "python\n",
    "CopyEdit\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmatized_words = [lemmatizer.lemmatize(word) for word in words]\n",
    "```\n",
    "\n",
    "``` python\n",
    "python\n",
    "CopyEdit\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "```\n",
    "\n",
    "### ðŸ”¹ Datetime Conversion\n",
    "\n",
    "### 1. **Convert to `datetime` Format**\n",
    "\n",
    "``` python\n",
    "python\n",
    "CopyEdit\n",
    "import pandas as pd\n",
    "\n",
    "df['date'] = pd.to_datetime(df['date'])  # auto-parses many formats\n",
    "```\n",
    "\n",
    "-   Got a custom format? Use `format`:\n",
    "\n",
    "    ``` python\n",
    "    python\n",
    "    CopyEdit\n",
    "    df['date'] = pd.to_datetime(df['date'], format='%d-%m-%Y')\n",
    "    ```\n",
    "\n",
    "### 2. **Handle Inconsistent Timestamps**\n",
    "\n",
    "Real-world timestamps can be messy â€” mixed formats, missing values,\n",
    "timezone weirdness\n",
    "\n",
    "### Fixing mixed or garbage formats:\n",
    "\n",
    "``` python\n",
    "python\n",
    "CopyEdit\n",
    "df['date'] = pd.to_datetime(df['date'], errors='coerce')  # invalid dates become NaT\n",
    "```\n",
    "\n",
    "### Timezone handling:\n",
    "\n",
    "``` python\n",
    "python\n",
    "CopyEdit\n",
    "df['date'] = df['date'].dt.tz_localize('UTC')            # localize naive timestamp\n",
    "df['date'] = df['date'].dt.tz_convert('Asia/Kolkata')    # c\n",
    "```"
   ],
   "id": "42a14256-91c8-446e-92a7-ab6bf11055d3"
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {}
}
