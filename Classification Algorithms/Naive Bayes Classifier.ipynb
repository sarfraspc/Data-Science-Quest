{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Classifier\n",
    "\n",
    "### **1. GaussianNB()**\n",
    "\n",
    "-   **What**: **Gaussian Naive Bayes** is used when the features are\n",
    "    continuous and assumed to follow a **Gaussian (Normal)\n",
    "    distribution**.\n",
    "\n",
    "-   **How it works**:\n",
    "\n",
    "    -   The model assumes that for each class, the features follow a\n",
    "        normal distribution (bell curve).\n",
    "    -   For each feature, it computes the mean and variance of the data\n",
    "        for each class and uses them to predict the class label for new\n",
    "        data.\n",
    "\n",
    "-   **When to use**:\n",
    "\n",
    "    -   Use **GaussianNB** when your data consists of **continuous\n",
    "        features** that are normally distributed (e.g., height, weight,\n",
    "        or test scores).\n",
    "\n",
    "-   **Example**:\n",
    "\n",
    "    ``` python\n",
    "    python\n",
    "    CopyEdit\n",
    "    from sklearn.naive_bayes import GaussianNB\n",
    "    gnb = GaussianNB()\n",
    "    gnb.fit(X_train, y_train)\n",
    "    ```\n",
    "\n",
    "### **2. MultinomialNB()**\n",
    "\n",
    "-   **What**: **Multinomial Naive Bayes** is used for **discrete count\n",
    "    data** or **categorical data** that is often modeled using the\n",
    "    **multinomial distribution**.\n",
    "\n",
    "-   **How it works**:\n",
    "\n",
    "    -   It’s commonly used for text classification where features are\n",
    "        the **word counts** (e.g., number of times a word appears in a\n",
    "        document).\n",
    "    -   It works by computing the likelihood of each class based on the\n",
    "        counts of features (e.g., words).\n",
    "\n",
    "-   **When to use**:\n",
    "\n",
    "    -   **MultinomialNB** is great for datasets where features represent\n",
    "        **counts** or **frequency** (e.g., word count vectors in NLP\n",
    "        tasks).\n",
    "\n",
    "-   **Example**:\n",
    "\n",
    "    ``` python\n",
    "    python\n",
    "    CopyEdit\n",
    "    from sklearn.naive_bayes import MultinomialNB\n",
    "    mnb = MultinomialNB()\n",
    "    mnb.fit(X_train, y_train)\n",
    "    ```\n",
    "\n",
    "### **3. BernoulliNB()**\n",
    "\n",
    "-   **What**: **Bernoulli Naive Bayes** is used when the features are\n",
    "    binary (0 or 1), i.e., they represent the presence or absence of a\n",
    "    particular feature.\n",
    "\n",
    "-   **How it works**:\n",
    "\n",
    "    -   The model assumes that the features follow a **Bernoulli\n",
    "        distribution** (each feature is either present or absent,\n",
    "        encoded as 1 or 0).\n",
    "\n",
    "-   **When to use**:\n",
    "\n",
    "    -   **BernoulliNB** is good when the features represent binary data,\n",
    "        like the presence or absence of a word in a text document (e.g.,\n",
    "        binary bag-of-words).\n",
    "\n",
    "-   **Example**:\n",
    "\n",
    "    ``` python\n",
    "    python\n",
    "    CopyEdit\n",
    "    from sklearn.naive_bayes import BernoulliNB\n",
    "    bnb = BernoulliNB()\n",
    "    bnb.fit(X_train, y_train)\n",
    "    ```\n",
    "\n",
    "### **4. ComplementNB()**\n",
    "\n",
    "-   **What**: **Complement Naive Bayes** is a variant of\n",
    "    **MultinomialNB** and is designed to handle **imbalanced datasets**\n",
    "    better.\n",
    "\n",
    "-   **How it works**:\n",
    "\n",
    "    -   It tries to correct the bias in **MultinomialNB** when the\n",
    "        classes are imbalanced by computing a “complement” or a\n",
    "        corrective measure to balance the influence of each class.\n",
    "\n",
    "-   **When to use**:\n",
    "\n",
    "    -   **ComplementNB** is helpful when your data has imbalanced\n",
    "        classes.\n",
    "\n",
    "-   **Example**:\n",
    "\n",
    "    ``` python\n",
    "    python\n",
    "    CopyEdit\n",
    "    from sklearn.naive_bayes import ComplementNB\n",
    "    cnb = ComplementNB()\n",
    "    cnb.fit(X_train, y_train)\n",
    "    ```\n",
    "\n",
    "-   Iris\n",
    "\n",
    "    ``` python\n",
    "    import pandas as pd\n",
    "    from sklearn.datasets import load_iris\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.naive_bayes import GaussianNB\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "    import seaborn as sns\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    # Load data\n",
    "    iris = load_iris()\n",
    "    X = iris.data\n",
    "    y = iris.target\n",
    "\n",
    "    # Scale\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    # Train-test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Model\n",
    "    model = GaussianNB()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Predict & evaluate\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(f\"Iris Accuracy: {accuracy_score(y_test, y_pred) * 100:.2f}%\")\n",
    "    sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, cmap='Blues', xticklabels=iris.target_names, yticklabels=iris.target_names)\n",
    "    plt.title(\"Confusion Matrix - Iris\")\n",
    "    plt.show()\n",
    "    print(classification_report(y_test, y_pred, target_names=iris.target_names))\n",
    "    ```\n",
    "\n",
    "-   Breast Cancer Wisconsin\n",
    "\n",
    "    ``` python\n",
    "    df = pd.read_csv('breast_cancer.csv')\n",
    "    df = df.loc[:, ~df.columns.str.contains('^Unnamed|id', case=False)]\n",
    "    df['diagnosis'] = df['diagnosis'].map({'M': 1, 'B': 0})\n",
    "\n",
    "    X = df.drop('diagnosis', axis=1)\n",
    "    y = df['diagnosis']\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    model = GaussianNB()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(f\"Breast Cancer Accuracy: {accuracy_score(y_test, y_pred) * 100:.2f}%\")\n",
    "    sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, cmap='Blues', xticklabels=['Benign', 'Malignant'], yticklabels=['Benign', 'Malignant'])\n",
    "    plt.title(\"Confusion Matrix - Breast Cancer\")\n",
    "    plt.show()\n",
    "    print(classification_report(y_test, y_pred, target_names=['Benign', 'Malignant']))\n",
    "    ```\n",
    "\n",
    "-   Titanic\n",
    "\n",
    "    ``` python\n",
    "    # Titanic: assumes you have a preprocessed CSV with no missing values\n",
    "    df = pd.read_csv('titanic.csv')\n",
    "\n",
    "    # Example preprocessing (adjust based on your CSV)\n",
    "    df = df[['Pclass', 'Sex', 'Age', 'Fare', 'Survived']]\n",
    "    df.dropna(inplace=True)\n",
    "    df['Sex'] = df['Sex'].map({'male': 0, 'female': 1})\n",
    "\n",
    "    X = df.drop('Survived', axis=1)\n",
    "    y = df['Survived']\n",
    "\n",
    "    # Scale\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    # Train-test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Naive Bayes\n",
    "    model = GaussianNB()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Predict & evaluate\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(f\"Titanic Accuracy: {accuracy_score(y_test, y_pred) * 100:.2f}%\")\n",
    "    sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, cmap='Blues', xticklabels=['Died', 'Survived'], yticklabels=['Died', 'Survived'])\n",
    "    plt.title(\"Confusion Matrix - Titanic\")\n",
    "    plt.show()\n",
    "    print(classification_report(y_test, y_pred, target_names=['Died', 'Survived']))\n",
    "    ```"
   ],
   "id": "42a14256-91c8-446e-92a7-ab6bf11055d3"
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {}
}
