{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistics\n",
    "\n",
    "concentrate more on those which I stared\n",
    "\n",
    "## Manual\n",
    "\n",
    "### Descriptive Stats and **Variability**\\*\n",
    "\n",
    "``` python\n",
    "# Manual Calculation of Mean, Median, Mode, Range, Variance, Standard Deviation, and IQR\n",
    "\n",
    "def mean(data):\n",
    "    total = sum(data)\n",
    "    count = len(data)\n",
    "    return total / count\n",
    "\n",
    "def median(data):\n",
    "    sorted_data = sorted(data)\n",
    "    n = len(sorted_data)\n",
    "    mid = n // 2\n",
    "    if n % 2 == 0:\n",
    "        return (sorted_data[mid - 1] + sorted_data[mid]) / 2\n",
    "    else:\n",
    "        return sorted_data[mid]\n",
    "\n",
    "def mode(data):\n",
    "    freq = {}\n",
    "    for num in data:\n",
    "        freq[num] = freq.get(num, 0) + 1\n",
    "    max_freq = max(freq.values())\n",
    "    modes = [key for key, value in freq.items() if value == max_freq]\n",
    "    return modes\n",
    "\n",
    "def data_range(data):\n",
    "    return max(data) - min(data)\n",
    "\n",
    "def variance(data):\n",
    "    m = mean(data)\n",
    "    return sum((x - m) ** 2 for x in data) / (len(data) - 1)  # Sample variance\n",
    "\n",
    "def standard_deviation(data):\n",
    "    return variance(data) ** 0.5\n",
    "\n",
    "def calculate_iqr(data):\n",
    "    sorted_data = sorted(data)\n",
    "    n = len(sorted_data)\n",
    "    \n",
    "    def find_median(values):\n",
    "        size = len(values)\n",
    "        mid = size // 2\n",
    "        return (values[mid - 1] + values[mid]) / 2 if size % 2 == 0 else values[mid]\n",
    "    \n",
    "    lower_half = sorted_data[:n//2] if n % 2 == 0 else sorted_data[:n//2]\n",
    "    upper_half = sorted_data[n//2:] if n % 2 == 0 else sorted_data[n//2+1:]\n",
    "    q1 = find_median(lower_half)\n",
    "    q3 = find_median(upper_half)\n",
    "    return q3 - q1, q1, q3\n",
    "\n",
    "# Sample Data\n",
    "data = [5, 2, 3, 6, 74, 9, 86, 21, 22, 385]\n",
    "\n",
    "print(\"Mean:\", mean(data))\n",
    "print(\"Median:\", median(data))\n",
    "print(\"Mode:\", mode(data))\n",
    "print(\"Range:\", data_range(data))\n",
    "print(\"Variance:\", variance(data))\n",
    "print(\"Standard Deviation:\", standard_deviation(data))\n",
    "iqr, q1, q3 = calculate_iqr(data)\n",
    "print(f\"IQR: {iqr}, Q1: {q1}, Q3: {q3}\")\n",
    "```\n",
    "\n",
    "### Covariance and Correlation \\*\n",
    "\n",
    "``` python\n",
    "# Manual Calculation of Covariance & Correlation\n",
    "\n",
    "def mean(data):\n",
    "    return sum(data) / len(data)\n",
    "\n",
    "def covariance(X, Y):\n",
    "    n = len(X)\n",
    "    mean_x, mean_y = mean(X), mean(Y)\n",
    "    return sum((x - mean_x) * (y - mean_y) for x, y in zip(X, Y)) / (n - 1)  # Sample covariance\n",
    "\n",
    "def population_covariance(X, Y):\n",
    "    n = len(X)\n",
    "    mean_x, mean_y = mean(X), mean(Y)\n",
    "    return sum((x - mean_x) * (y - mean_y) for x, y in zip(X, Y)) / n\n",
    "\n",
    "def variance(data):\n",
    "    m = mean(data)\n",
    "    return sum((x - m) ** 2 for x in data) / (len(data) - 1)  # Sample variance\n",
    "\n",
    "def standard_deviation(data):\n",
    "    return variance(data) ** 0.5\n",
    "\n",
    "def correlation(X, Y):\n",
    "    return covariance(X, Y) / (standard_deviation(X) * standard_deviation(Y))\n",
    "\n",
    "# Sample Data\n",
    "X = [3, 5, 7, 9, 11]\n",
    "Y = [2, 4, 6, 8, 10]\n",
    "\n",
    "print(\"Covariance:\", covariance(X, Y))\n",
    "print(\"Population Covariance:\", population_covariance(X, Y))\n",
    "print(\"Correlation:\", correlation(X, Y))\n",
    "```\n",
    "\n",
    "### Probability Basics\\*\n",
    "\n",
    "``` python\n",
    "def addition_rule(p_A, p_B, p_A_and_B):\n",
    "    return p_A + p_B - p_A_and_B\n",
    "\n",
    "def multiplication_rule_independent(p_A, p_B):\n",
    "    return p_A * p_B\n",
    "\n",
    "def expectation(values, probabilities):\n",
    "    return sum(v * p for v, p in zip(values, probabilities))\n",
    "\n",
    "# Example\n",
    "print(\"P(A or B):\", addition_rule(0.4, 0.3, 0.1))\n",
    "print(\"P(A and B, independent):\", multiplication_rule_independent(0.4, 0.3))\n",
    "print(\"Expectation:\", expectation([0, 1, 2], [0.5, 0.3, 0.2]))\n",
    "```\n",
    "\n",
    "### hypothesis \\*\n",
    "\n",
    "### **1️⃣ One-Sample t-Test**\n",
    "\n",
    "``` python\n",
    "python\n",
    "Copy code\n",
    "# One-Sample t-Test (Manual)\n",
    "\n",
    "sample = [22, 24, 27, 23, 26, 30, 28, 25, 29, 24]\n",
    "n = len(sample)\n",
    "population_mean = 25\n",
    "\n",
    "# Calculate mean\n",
    "sample_mean = sum(sample) / n\n",
    "\n",
    "# Calculate standard deviation\n",
    "variance = sum((x - sample_mean) ** 2 for x in sample) / (n - 1)\n",
    "sample_std = variance ** 0.5\n",
    "\n",
    "# Calculate t-score\n",
    "t_score = (sample_mean - population_mean) / (sample_std / (n ** 0.5))\n",
    "\n",
    "print(\"T-Statistic:\", t_score)\n",
    "```\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "### **2️⃣ Independent t-Test**\n",
    "\n",
    "``` python\n",
    "python\n",
    "Copy code\n",
    "# Independent t-Test (Manual)\n",
    "\n",
    "sample1 = [22, 24, 27, 23, 26]\n",
    "sample2 = [30, 28, 25, 29, 24]\n",
    "\n",
    "n1, n2 = len(sample1), len(sample2)\n",
    "\n",
    "mean1 = sum(sample1) / n1\n",
    "mean2 = sum(sample2) / n2\n",
    "\n",
    "# Calculate variances\n",
    "var1 = sum((x - mean1) ** 2 for x in sample1) / (n1 - 1)\n",
    "var2 = sum((x - mean2) ** 2 for x in sample2) / (n2 - 1)\n",
    "\n",
    "# Pooled standard deviation\n",
    "pooled_variance = ((n1 - 1) * var1 + (n2 - 1) * var2) / (n1 + n2 - 2)\n",
    "\n",
    "# Compute t-score\n",
    "t_score = (mean1 - mean2) / pooled_std\n",
    "\n",
    "print(\"T-Statistic:\", t_score)\n",
    "```\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "### **3️⃣ Paired t-Test**\n",
    "\n",
    "``` python\n",
    "python\n",
    "Copy code\n",
    "# Paired t-Test (Manual)\n",
    "\n",
    "before = [22, 24, 28, 23, 26]\n",
    "after = [30, 28, 25, 29, 24]\n",
    "\n",
    "n = len(before)\n",
    "\n",
    "# Calculate differences\n",
    "differences = [after[i] - before[i] for i in range(n)]\n",
    "\n",
    "# Calculate mean of differences\n",
    "mean_diff = sum(differences) / n\n",
    "\n",
    "# Calculate standard deviation of differences\n",
    "variance = sum((x - mean_diff) ** 2 for x in differences) / (n - 1)\n",
    "std_diff = variance ** 0.5\n",
    "\n",
    "# Compute t-score\n",
    "t_score = mean_diff / (std_diff / (n ** 0.5))\n",
    "\n",
    "print(\"T-Statistic:\", t_score)\n",
    "```\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "### **4️⃣ Chi-Square Test**\n",
    "\n",
    "``` python\n",
    "python\n",
    "Copy code\n",
    "# Chi-Square Test (Manual)\n",
    "\n",
    "observed = [[50, 30], [20, 40]]\n",
    "\n",
    "# Calculate row and column sums\n",
    "row_sums = [sum(row) for row in observed]\n",
    "col_sums = [sum(col) for col in zip(*observed)]\n",
    "total = sum(row_sums)\n",
    "\n",
    "# Expected values\n",
    "expected = [[(row_sums[i] * col_sums[j]) / total for j in range(len(col_sums))] for i in range(len(row_sums))]\n",
    "\n",
    "# Compute Chi-Square statistic\n",
    "chi_square = sum((observed[i][j] - expected[i][j]) ** 2 / expected[i][j] for i in range(len(observed)) for j in range(len(observed[0])))\n",
    "\n",
    "print(\"Chi-Square Statistic:\", chi_square)\n",
    "```\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "### **5️⃣ One-Way ANOVA**\n",
    "\n",
    "``` python\n",
    "python\n",
    "Copy code\n",
    "# One-Way ANOVA (Manual)\n",
    "\n",
    "group1 = [70, 75, 80, 85, 90]\n",
    "group2 = [60, 65, 70, 75, 80]\n",
    "group3 = [50, 55, 60, 65, 70]\n",
    "\n",
    "all_data = group1 + group2 + group3\n",
    "k = 3  # Number of groups\n",
    "n = len(all_data)  # Total number of observations\n",
    "\n",
    "# Calculate means\n",
    "group_means = [sum(g) / len(g) for g in [group1, group2, group3]]\n",
    "grand_mean = sum(all_data) / n\n",
    "\n",
    "# Between-group variance (SSB)\n",
    "ssb = sum(len(g) * (mean - grand_mean) ** 2 for g, mean in zip([group1, group2, group3], group_means))\n",
    "\n",
    "# Within-group variance (SSW)\n",
    "ssw = sum(sum((x - mean) ** 2 for x in g) for g, mean in zip([group1, group2, group3], group_means))\n",
    "\n",
    "# Degrees of freedom\n",
    "df_between = k - 1\n",
    "df_within = n - k\n",
    "\n",
    "# Mean Squares\n",
    "msb = ssb / df_between\n",
    "msw = ssw / df_within\n",
    "\n",
    "# Compute F-statistic\n",
    "f_statistic = msb / msw\n",
    "\n",
    "print(\"F-Statistic:\", f_statistic)\n",
    "```\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "### **6️⃣ Two-Way ANOVA (Manual Calculation)**\n",
    "\n",
    "``` python\n",
    "python\n",
    "Copy code\n",
    "# Two-Way ANOVA (Manual)\n",
    "\n",
    "groups = {\n",
    "    \"A_short\": [88, 85, 87],\n",
    "    \"A_long\": [75, 78, 80],\n",
    "    \"B_short\": [90, 92, 89],\n",
    "    \"B_long\": [70, 72, 68],\n",
    "    \"C_short\": [80, 78, 82],\n",
    "    \"C_long\": [60, 63, 59],\n",
    "}\n",
    "\n",
    "all_data = sum(groups.values(), [])\n",
    "total_mean = sum(all_data) / len(all_data)\n",
    "\n",
    "# Calculate means\n",
    "group_means = {k: sum(v) / len(v) for k, v in groups.items()}\n",
    "\n",
    "# Between-group variance (SSB)\n",
    "ssb = sum(len(v) * (mean - total_mean) ** 2 for v, mean in group_means.items())\n",
    "\n",
    "# Within-group variance (SSW)\n",
    "ssw = sum(sum((x - mean) ** 2 for x in v) for v, mean in group_means.items())\n",
    "\n",
    "# Compute F-statistic\n",
    "f_statistic = (ssb / (len(groups) - 1)) / (ssw / (len(all_data) - len(groups)))\n",
    "\n",
    "print(\"F-Statistic:\", f_statistic)\n",
    "```\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "### **7️⃣ One-Sample Z-Test**\n",
    "\n",
    "``` python\n",
    "python\n",
    "Copy code\n",
    "# One-Sample Z-Test (Manual)\n",
    "\n",
    "sample_mean = 50\n",
    "population_mean = 50\n",
    "population_sd = 3\n",
    "n = 40\n",
    "\n",
    "# Compute Z-score\n",
    "z_score = (sample_mean - population_mean) / (population_sd / (n ** 0.5))\n",
    "\n",
    "print(\"Z-Score:\", z_score)\n",
    "```\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "### **8️⃣ Two-Sample Z-Test**\n",
    "\n",
    "``` python\n",
    "python\n",
    "Copy code\n",
    "# Two-Sample Z-Test (Manual)\n",
    "\n",
    "mean1 = 53\n",
    "mean2 = 47\n",
    "sd1 = 3\n",
    "sd2 = 4\n",
    "\n",
    "n1 = 40\n",
    "n2 = 40\n",
    "\n",
    "# Compute Z-score\n",
    "z_score = (mean1 - mean2) / (((sd1 ** 2) / n1 + (sd2 ** 2) / n2) ** 0.5)\n",
    "\n",
    "print(\"Z-Score:\", z_score)\n",
    "```\n",
    "\n",
    "### skewness and kurtosis\\*\n",
    "\n",
    "``` python\n",
    "# Manual Skewness and Kurtosis\n",
    "def skewness(data):\n",
    "    n = len(data)\n",
    "    m = mean(data)\n",
    "    s = standard_deviation(data)\n",
    "    return sum((x - m) ** 3 for x in data) / (n * s ** 3)\n",
    "\n",
    "def kurtosis_manual(data):\n",
    "    n = len(data)\n",
    "    m = mean(data)\n",
    "    s = standard_deviation(data)\n",
    "    return sum((x - m) ** 4 for x in data) / (n * s ** 4) - 3  # Excess kurtosis\n",
    "\n",
    "# Example\n",
    "data = [5, 2, 3, 6, 74, 9, 86, 21, 22, 385]\n",
    "print(\"Skewness:\", skewness(data))\n",
    "print(\"Kurtosis:\", kurtosis_manual(data))\n",
    "```\n",
    "\n",
    "### Probability Distributions\n",
    "\n",
    "``` python\n",
    "# Manual Probability Distributions\n",
    "\n",
    "def factorial(n):\n",
    "    return 1 if n <= 1 else n * factorial(n - 1)\n",
    "\n",
    "# Uniform Distribution\n",
    "def uniform_probability(n):\n",
    "    return 1 / n  # Each outcome has equal probability\n",
    "\n",
    "# Binomial Distribution\n",
    "#Formula: 𝑛!/𝑘!(𝑛−𝑘)!\n",
    "def combination(n, k):\n",
    "    return factorial(n) // (factorial(k) * factorial(n - k))\n",
    "#Formula: Probability=combinations×(𝑝^𝑘)×(1−𝑝)^𝑛−𝑘\n",
    "    def binomial_probability(n, k, p):\n",
    "    return combination(n, k) * (p ** k) * ((1 - p) ** (n - k))\n",
    "\n",
    "# Normal Distribution (Approximation)f(x) = [1 / (σ × √(2π))] × e^[-((x - μ)^2) / (2σ^2)]\n",
    "def normal_distribution(x, mean, std_dev):\n",
    "    e = 2.71828  # Approximation of e\n",
    "    pi = 3.14159  # Approximation of pi\n",
    "    exponent = -((x - mean) ** 2) / (2 * (std_dev ** 2))\n",
    "    coefficient = 1 / (std_dev * ((2 * pi) ** 0.5))\n",
    "    return coefficient * (e ** exponent)\n",
    "\n",
    "# Bernoulli Distribution\n",
    "def bernoulli_pmf(k, p):\n",
    "    if k == 1:\n",
    "        return p\n",
    "    elif k == 0:\n",
    "        return 1 - p\n",
    "    return 0\n",
    "\n",
    "# Poisson Distribution-P(X = k) = (e^(-λ) * λ^k) / k!\n",
    "def poisson_pmf(k, mu):\n",
    "    e = 2.71828\n",
    "    return (mu ** k) * (e ** -mu) / factorial(k)\n",
    "\n",
    "# Exponential Distribution-**f(x; λ) = λ * e^(-λx),  for x ≥ 0**\n",
    "def exponential_pdf(x, scale):  # scale = 1/lambda-\n",
    "    e = 2.71828\n",
    "    if x >= 0:\n",
    "        return (1 / scale) * (e ** (-x / scale))\n",
    "    return 0\n",
    "\n",
    "def exponential_cdf(x, scale):\n",
    "    e = 2.71828\n",
    "    if x >= 0:\n",
    "        return 1 - (e ** (-x / scale))\n",
    "    return 0\n",
    "\n",
    "# Geometric Distribution\n",
    "def geometric_pmf(k, p):\n",
    "    if k < 1:\n",
    "        return 0\n",
    "    return (1 - p) ** (k - 1) * p\n",
    "\n",
    "def geometric_cdf(k, p):\n",
    "    if k < 1:\n",
    "        return 0\n",
    "    return 1 - (1 - p) ** k\n",
    "\n",
    "# Beta Distribution (Simplified PDF, requires numerical integration for CDF)\n",
    "def beta_pdf(x, alpha, beta_param):\n",
    "    if 0 <= x <= 1:\n",
    "        # Approximation of Beta function: B(a,b) = Γ(a)Γ(b)/Γ(a+b) ≈ factorial-based\n",
    "        B = factorial(alpha - 1) * factorial(beta_param - 1) / factorial(alpha + beta_param - 2)\n",
    "        return (x ** (alpha - 1)) * ((1 - x) ** (beta_param - 1)) / B\n",
    "    return 0\n",
    "\n",
    "# Gamma Distribution (Simplified PDF)\n",
    "def gamma_pdf(x, shape, scale):\n",
    "    e = 2.71828\n",
    "    if x >= 0:\n",
    "        return (x ** (shape - 1)) * (e ** (-x / scale)) / (scale ** shape * factorial(shape - 1))\n",
    "    return 0\n",
    "\n",
    "# Multinomial Distribution\n",
    "def multinomial_pmf(x, n, p):\n",
    "    if sum(x) != n or len(x) != len(p):\n",
    "        return 0\n",
    "    numerator = factorial(n)\n",
    "    denominator = 1\n",
    "    for xi in x:\n",
    "        denominator *= factorial(xi)\n",
    "    prob = 1\n",
    "    for xi, pi in zip(x, p):\n",
    "        prob *= pi ** xi\n",
    "    return numerator / denominator * prob\n",
    "\n",
    "# Examples\n",
    "print(\"Uniform P(1 outcome, n=6):\", uniform_probability(6))\n",
    "print(\"Binomial P(k=2, n=3, p=0.5):\", binomial_probability(3, 2, 0.5))\n",
    "print(\"Normal f(x=1, mu=0, sigma=1):\", normal_distribution(1, 0, 1))\n",
    "print(\"Bernoulli P(k=1, p=0.6):\", bernoulli_pmf(1, 0.6))\n",
    "print(\"Poisson P(k=2, mu=3):\", poisson_pmf(2, 3))\n",
    "print(\"Exponential f(x=1, scale=2):\", exponential_pdf(1, 2))\n",
    "print(\"Geometric P(k=3, p=0.3):\", geometric_pmf(3, 0.3))\n",
    "print(\"Beta f(x=0.4, alpha=2, beta=5):\", beta_pdf(0.4, 2, 5))\n",
    "print(\"Gamma f(x=3, shape=2, scale=2):\", gamma_pdf(3, 2, 2))\n",
    "print(\"Multinomial P([1,1,3], n=5, p=[0.2,0.3,0.5]):\", multinomial_pmf([1, 1, 3], 5, [0.2, 0.3, 0.5]))\n",
    "```\n",
    "\n",
    "### PMF,PDF and CDF\n",
    "\n",
    "**Probability Mass Function (PMF)**\n",
    "\n",
    "``` python\n",
    "def calculate_pmf(data, x):\n",
    "    total_count = len(data)\n",
    "    occurrence = sum(1 for i in data if i == x)  # Count occurrences of x\n",
    "    return occurrence / total_count\n",
    "\n",
    "# Example dataset\n",
    "data = [1, 2, 2, 3, 3, 3, 4, 4, 4, 4]  # Discrete values\n",
    "x = 3  # Find probability of 3 occurring\n",
    "\n",
    "print(\"Manual PMF for X=3:\", calculate_pmf(data, x))\n",
    "```\n",
    "\n",
    "**Probability Density Function (PDF)**\n",
    "\n",
    "``` python\n",
    "def power(base, exp):\n",
    "    result = 1\n",
    "    for _ in range(abs(exp)):\n",
    "        result *= base\n",
    "    return result if exp >= 0 else 1 / result  # Handle negative exponents\n",
    "\n",
    "def factorial(n):\n",
    "    result = 1\n",
    "    for i in range(1, n + 1):\n",
    "        result *= i\n",
    "    return result\n",
    "\n",
    "def sqrt(n, precision=10):\n",
    "    x = n\n",
    "    for _ in range(precision):\n",
    "        x = 0.5 * (x + n / x)  # Babylonian method\n",
    "    return x\n",
    "\n",
    "def exp_manual(x, terms=20):\n",
    "    total = 1  # e^0 = 1\n",
    "    for n in range(1, terms):\n",
    "        total += power(x, n) / factorial(n)  # Taylor series expansion\n",
    "    return total\n",
    "\n",
    "def normal_pdf(x, mean, std):\n",
    "    pi = 3.1415926535\n",
    "    e = exp_manual(1)  # Approximate e\n",
    "\n",
    "    coeff = 1 / (std * sqrt(2 * pi))\n",
    "    exponent = exp_manual(-((x - mean) ** 2) / (2 * std ** 2))\n",
    "    return coeff * exponent\n",
    "\n",
    "# Example values\n",
    "mean = 50\n",
    "std = 10\n",
    "x_value = 55  # Find probability at X = 55\n",
    "\n",
    "print(\"Manual Normal PDF for X=55:\", normal_pdf(x_value, mean, std))\n",
    "```\n",
    "\n",
    "**Cumulative Distribution Function (CDF)**\n",
    "\n",
    "``` python\n",
    "def erf_manual(x, terms=10):\n",
    "    pi = 3.1415926535\n",
    "    sum_erf = 0\n",
    "\n",
    "    for n in range(terms):\n",
    "        sum_erf += ((-1) ** n * power(x, 2 * n + 1)) / ((2 * n + 1) * factorial(n))\n",
    "    \n",
    "    return (2 / sqrt(pi)) * sum_erf\n",
    "\n",
    "def normal_cdf(x, mean, std):\n",
    "    return 0.5 * (1 + erf_manual((x - mean) / (std * sqrt(2))))\n",
    "\n",
    "print(\"Manual Normal CDF for X=55:\", normal_cdf(x_value, mean, std))\n",
    "```\n",
    "\n",
    "### Bias/Variance Tradeoff\n",
    "\n",
    "``` python\n",
    "def bias_variance_simulation(true_value, samples):\n",
    "    n = len(samples)\n",
    "    sample_means = [mean(sample) for sample in samples]\n",
    "    estimator_mean = mean(sample_means)\n",
    "    bias = estimator_mean - true_value\n",
    "    variance = sum((m - estimator_mean) ** 2 for m in sample_means) / (n - 1)\n",
    "    return bias, variance\n",
    "\n",
    "# Example\n",
    "true_mean = 10\n",
    "samples = [[9, 10, 11], [8, 9, 12], [10, 11, 12]]\n",
    "bias, var = bias_variance_simulation(true_mean, samples)\n",
    "print(f\"Bias: {bias}, Variance: {var}\")\n",
    "```\n",
    "\n",
    "### Vector Calculus\n",
    "\n",
    "``` python\n",
    "def derivative_univariate(func, x, h=0.0001):\n",
    "    return (func(x + h) - func(x)) / h\n",
    "\n",
    "def partial_derivative_x(func, x, y, h=0.0001):\n",
    "    return (func(x + h, y) - func(x, y)) / h\n",
    "\n",
    "def gradient(func, x, y, h=0.0001):\n",
    "    df_dx = partial_derivative_x(func, x, y, h)\n",
    "    df_dy = (func(x, y + h) - func(x, y)) / h\n",
    "    return [df_dx, df_dy]\n",
    "\n",
    "# Example\n",
    "def f_univariate(x):\n",
    "    return x ** 2\n",
    "\n",
    "def f_bivariate(x, y):\n",
    "    return x ** 2 + y ** 2\n",
    "\n",
    "print(\"Univariate Derivative f(x)=x^2 at x=2:\", derivative_univariate(f_univariate, 2))\n",
    "print(\"Gradient f(x,y)=x^2+y^2 at (2,3):\", gradient(f_bivariate, 2, 3))\n",
    "```\n",
    "\n",
    "### Central Limit Theorem\n",
    "\n",
    "``` python\n",
    "def clt_simulation(population, sample_size, num_samples):\n",
    "    sample_means = []\n",
    "    for _ in range(num_samples):\n",
    "        sample = [population[i % len(population)] for i in range(sample_size)]\n",
    "        sample_means.append(mean(sample))\n",
    "    return mean(sample_means), variance(sample_means)\n",
    "\n",
    "# Example\n",
    "population = [1, 2, 3, 4, 5, 6]\n",
    "print(\"CLT Mean, Variance:\", clt_simulation(population, 10, 100))\n",
    "```\n",
    "\n",
    "### Sampling\n",
    "\n",
    "``` python\n",
    "def simple_random_sample(population, sample_size):\n",
    "    n = len(population)\n",
    "    sample = []\n",
    "    indices = list(range(n))\n",
    "    for _ in range(sample_size):\n",
    "        idx = indices.pop(int(mean(indices)) % len(indices))\n",
    "        sample.append(population[idx])\n",
    "    return sample\n",
    "\n",
    "# Example\n",
    "population = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "print(\"Random Sample:\", simple_random_sample(population, 3))\n",
    "```\n",
    "\n",
    "### Optimization Techniques\n",
    "\n",
    "``` python\n",
    "def gradient_descent(func, start_x, learning_rate=0.1, iterations=100):\n",
    "    x = start_x\n",
    "    for _ in range(iterations):\n",
    "        grad = derivative_univariate(func, x)\n",
    "        x -= learning_rate * grad\n",
    "    return x\n",
    "\n",
    "# Example\n",
    "def f(x):\n",
    "    return x ** 2\n",
    "\n",
    "print(\"Optimal x for f(x)=x^2:\", gradient_descent(f, 2))\n",
    "```\n",
    "\n",
    "## Libraries\n",
    "\n",
    "### Probability Distributions \\*\n",
    "\n",
    "``` python\n",
    "from scipy import stats\n",
    "#General Order in SciPy\n",
    "#For Discrete Distributions (PMF) → (k, n, p, loc)\n",
    "#For Continuous Distributions (PDF) → (x, shape, scale, loc)\n",
    "\n",
    "# Probability Distributions using SciPy\n",
    "print(\"Uniform P(X=5, a=0, b=10):\", stats.uniform.pdf(5, loc=0, scale=10))\n",
    "print(\"Binomial P(k=2, n=3, p=0.5):\", stats.binom.pmf(2, 3, 0.5))\n",
    "print(\"Normal f(x=1, mu=0, sigma=1):\", stats.norm.pdf(1, 0, 1))\n",
    "print(\"Bernoulli P(k=1, p=0.6):\", stats.bernoulli.pmf(1, 0.6))\n",
    "print(\"Poisson P(k=2, mu=3):\", stats.poisson.pmf(2, 3))\n",
    "print(\"Exponential f(x=1, scale=2):\", stats.expon.pdf(1, scale=2))\n",
    "print(\"Geometric P(k=3, p=0.3):\", stats.geom.pmf(3, 0.3))\n",
    "print(\"Beta f(x=0.4, alpha=2, beta=5):\", stats.beta.pdf(0.4, 2, 5))\n",
    "print(\"Gamma f(x=3, shape=2, scale=2):\", stats.gamma.pdf(3, 2, scale=2))\n",
    "print(\"Multinomial P([1,1,3], n=5, p=[0.2,0.3,0.5]):\", stats.multinomial.pmf([1, 1, 3], n=5, p=[0.2, 0.3, 0.5]))\n",
    "```\n",
    "\n",
    "### skewness and kurtosis\\*\n",
    "\n",
    "``` python\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "\n",
    "data = np.array([5, 2, 3, 6, 74, 9, 86, 21, 22, 385])\n",
    "skew_val = stats.skew(data)\n",
    "kurt_val = stats.kurtosis(data)\n",
    "print(\"Skewness:\", skew_val)\n",
    "print(\"Kurtosis:\", kurt_val)\n",
    "```\n",
    "\n",
    "**Plot**\n",
    "\n",
    "``` python\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import kurtosis, skew\n",
    "\n",
    "# Sample data\n",
    "data = np.random.gamma(2., 2., 1000)  # Example dataset\n",
    "\n",
    "# Calculate kurtosis and skewness\n",
    "data_kurtosis = kurtosis(data)\n",
    "data_skewness = skew(data)\n",
    "\n",
    "# Plot\n",
    "sns.histplot(data, kde=True, color='blue', alpha=0.6, bins=30)\n",
    "plt.title(f\"Distribution with Skewness: {data_skewness:.2f} and Kurtosis: {data_kurtosis:.2f}\")\n",
    "plt.xlabel(\"Value\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "### hypothesis \\*\n",
    "\n",
    "### **1️⃣ One-Sample t-Test** (Compare sample mean with population mean)\n",
    "\n",
    "``` python\n",
    "python\n",
    "Copy code\n",
    "from scipy import stats\n",
    "\n",
    "data = [22, 24, 27, 23, 26, 30, 28, 25, 29, 24]\n",
    "population_mean = 25\n",
    "\n",
    "t_statistic, p_value = stats.ttest_1samp(data, population_mean)\n",
    "\n",
    "print('T-statistic:', t_statistic)\n",
    "print('p-value:', p_value)\n",
    "\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print('Reject the null hypothesis')\n",
    "else:\n",
    "    print('Fail to reject the null hypothesis.')\n",
    "```\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "### **2️⃣ Independent t-Test** (Compare means of two independent groups)\n",
    "\n",
    "``` python\n",
    "python\n",
    "Copy code\n",
    "from scipy import stats\n",
    "\n",
    "sample1 = [22, 24, 27, 23, 26]\n",
    "sample2 = [30, 28, 25, 29, 24]\n",
    "\n",
    "t_statistic, p_value = stats.ttest_ind(sample1, sample2)\n",
    "\n",
    "print('T-statistic:', t_statistic)\n",
    "print('p-value:', p_value)\n",
    "\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print('Reject the null hypothesis')\n",
    "else:\n",
    "    print('Fail to reject the null hypothesis')\n",
    "```\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "### **3️⃣ Paired t-Test** (Compare before and after scores of the same group)\n",
    "\n",
    "``` python\n",
    "python\n",
    "Copy code\n",
    "from scipy import stats\n",
    "\n",
    "before = [22, 24, 28, 23, 26]\n",
    "after = [30, 28, 25, 29, 24]\n",
    "\n",
    "t_statistic, p_value = stats.ttest_rel(before, after)\n",
    "\n",
    "print('T-statistic:', t_statistic)\n",
    "print('p-value:', p_value)\n",
    "\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print('Reject the null hypothesis')\n",
    "else:\n",
    "    print('Fail to reject the null hypothesis')\n",
    "```\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "### **4️⃣ Chi-Square Test** (Check independence between categorical variables)\n",
    "\n",
    "``` python\n",
    "python\n",
    "Copy code\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "# Contingency table (rows & columns)\n",
    "data = [[50, 30], [20, 40]]\n",
    "\n",
    "chi2_stat, p_value, dof, expected = chi2_contingency(data)\n",
    "\n",
    "print('Chi-Square statistic:', chi2_stat)\n",
    "print('p-value:', p_value)\n",
    "\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print('Reject the null hypothesis')\n",
    "else:\n",
    "    print('Fail to reject the null hypothesis')\n",
    "```\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "### **5️⃣ One-Way ANOVA** (Compare means of 3+ independent groups)\n",
    "\n",
    "``` python\n",
    "python\n",
    "Copy code\n",
    "from scipy.stats import f_oneway\n",
    "\n",
    "group1 = [70, 75, 80, 85, 90]\n",
    "group2 = [60, 65, 70, 75, 80]\n",
    "group3 = [50, 55, 60, 65, 70]\n",
    "\n",
    "f_statistic, p_value = f_oneway(group1, group2, group3)\n",
    "\n",
    "print('F-statistic:', f_statistic)\n",
    "print('p-value:', p_value)\n",
    "\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print('Reject the null hypothesis')\n",
    "else:\n",
    "    print('Fail to reject the null hypothesis')\n",
    "```\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "### **6️⃣ Two-Way ANOVA (Manual Calculation)** (Check effects of 2 independent variables)\n",
    "\n",
    "``` python\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "# Sample Data: Two factors (Group & Condition)\n",
    "data = {\n",
    "    \"Score\":  [88, 85, 87, 75, 78, 80, 90, 92, 89, 70, 72, 68, 80, 78, 82, 60, 63, 59],\n",
    "    \"Group\":  [\"A\", \"A\", \"A\", \"A\", \"A\", \"A\", \"B\", \"B\", \"B\", \"B\", \"B\", \"B\", \"C\", \"C\", \"C\", \"C\", \"C\", \"C\"],\n",
    "    \"Condition\": [\"Short\", \"Short\", \"Short\", \"Long\", \"Long\", \"Long\",\n",
    "                  \"Short\", \"Short\", \"Short\", \"Long\", \"Long\", \"Long\",\n",
    "                  \"Short\", \"Short\", \"Short\", \"Long\", \"Long\", \"Long\"]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Fit Two-Way ANOVA model\n",
    "model = smf.ols('Score ~ C(Group) + C(Condition) + C(Group):C(Condition)', data=df).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)  # Type 2 ANOVA Table\n",
    "\n",
    "print(anova_table)\n",
    "```\n",
    "\n",
    "## 7️⃣**one sample z-test**\n",
    "\n",
    "``` python\n",
    "from scipy import stats \n",
    "import math\n",
    "\n",
    "sample_mean=50\n",
    "population_mean=50\n",
    "population_sd=3\n",
    "n=40\n",
    "z_score=(sample_mean-population_mean)/(population_sd/math.sqrt(n))\n",
    "p_value=2*(1-stats.norm.cdf(abs(z_score)))\n",
    "\n",
    "alpha = 0.05\n",
    "\n",
    "# Decision\n",
    "if p_value < alpha:\n",
    "    print('Reject the null hypothesis')\n",
    "else:\n",
    "    print('Fail to reject the null hypothesis')\n",
    "```\n",
    "\n",
    "## 8️⃣**two sample z-test**\n",
    "\n",
    "``` python\n",
    "from scipy import stats\n",
    "import math\n",
    "\n",
    "mean1=53\n",
    "mean2=47\n",
    "sd1=3\n",
    "sd2=4\n",
    "\n",
    "n1=40\n",
    "n2=40\n",
    "\n",
    "z_score=(mean1-mean2)/math.sqrt((sd1**2/n1)+(sd2**2)/n2)\n",
    "\n",
    "p_value=2*(1-stats.norm.cdf(abs(z_score)))\n",
    "\n",
    "# Significance level\n",
    "alpha = 0.05\n",
    "\n",
    "# Decision\n",
    "if p_value < alpha:\n",
    "    print('Reject the null hypothesis')\n",
    "else:\n",
    "    print('Fail to reject the null hypothesis')\n",
    "```\n",
    "\n",
    "### Descriptive Stats and **Variability-**\n",
    "\n",
    "``` python\n",
    "import numpy as np\n",
    "\n",
    "# Descriptive Statistics and Variability using NumPy\n",
    "data = np.array([5, 2, 3, 6, 74, 9, 86, 21, 22, 385])\n",
    "\n",
    "mean_val = np.mean(data)\n",
    "median_val = np.median(data)\n",
    "mode_val = np.unique(data, return_counts=True)[0][np.argmax(np.unique(data, return_counts=True)[1])]\n",
    "range_val = np.max(data) - np.min(data)\n",
    "variance_val = np.var(data, ddof=1)  # Sample variance\n",
    "std_dev_val = np.std(data, ddof=1)   # Sample standard deviation\n",
    "q1, q3 = np.percentile(data, [25, 75])\n",
    "iqr_val = q3 - q1\n",
    "\n",
    "print(\"Mean:\", mean_val)\n",
    "print(\"Median:\", median_val)\n",
    "print(\"Mode:\", mode_val)\n",
    "print(\"Range:\", range_val)\n",
    "print(\"Variance:\", variance_val)\n",
    "print(\"Standard Deviation:\", std_dev_val)\n",
    "print(f\"IQR: {iqr_val}, Q1: {q1}, Q3: {q3}\")\n",
    "```\n",
    "\n",
    "### Covariance and Correlation -\n",
    "\n",
    "``` python\n",
    "import numpy as np\n",
    "\n",
    "# Covariance and Correlation using NumPy\n",
    "X = np.array([3, 5, 7, 9, 11])\n",
    "Y = np.array([2, 4, 6, 8, 10])\n",
    "\n",
    "cov_matrix = np.cov(X, Y, ddof=1)  # Sample covariance\n",
    "cov_xy = cov_matrix[0, 1]\n",
    "pop_cov_xy = np.cov(X, Y, ddof=0)[0, 1]  # Population covariance\n",
    "pearson_corr = np.corrcoef(X, Y)[0, 1]\n",
    "\n",
    "from scipy.stats import spearmanr, kendalltau\n",
    "spearman_corr, _ = spearmanr(X, Y)\n",
    "kendall_corr, _ = kendalltau(X, Y)\n",
    "\n",
    "print(\"Sample Covariance:\", cov_xy)\n",
    "print(\"Population Covariance:\", pop_cov_xy)\n",
    "print(\"Pearson Correlation:\", pearson_corr)\n",
    "print(\"Spearman Correlation:\", spearman_corr)\n",
    "print(\"Kendall Correlation:\", kendall_corr)\n",
    "```\n",
    "\n",
    "### PMF,PDF and CDF\n",
    "\n",
    "``` python\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "\n",
    "# PMF\n",
    "data = np.array([1, 2, 2, 3, 3, 3, 4, 4, 4, 4])\n",
    "unique, counts = np.unique(data, return_counts=True)\n",
    "pmf = counts / len(data)\n",
    "print(\"PMF for X=3:\", pmf[unique == 3][0])\n",
    "\n",
    "# PDF and CDF (Normal Distribution)\n",
    "mean, std = 50, 10\n",
    "x = 55\n",
    "print(\"Normal PDF for X=55:\", stats.norm.pdf(x, mean, std))\n",
    "print(\"Normal CDF for X=55:\", stats.norm.cdf(x, mean, std))\n",
    "```\n",
    "\n",
    "### Bias/Variance Tradeoff\n",
    "\n",
    "``` python\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Bias and Variance (Simplified Example)\n",
    "true_value = 10\n",
    "samples = [np.array([9, 10, 11]), np.array([8, 9, 12]), np.array([10, 11, 12])]\n",
    "means = [np.mean(s) for s in samples]\n",
    "bias = np.mean(means) - true_value\n",
    "variance = np.var(means, ddof=1)\n",
    "print(f\"Bias: {bias}, Variance: {variance}\")\n",
    "```\n",
    "\n",
    "### Vector Calculus\n",
    "\n",
    "``` python\n",
    "import numpy as np\n",
    "from scipy.misc import derivative\n",
    "\n",
    "# Univariate Derivative\n",
    "def f(x):\n",
    "    return x ** 2\n",
    "print(\"Univariate Derivative at x=2:\", derivative(f, 2, dx=1e-6))\n",
    "\n",
    "# Gradient (Numerical)\n",
    "def f_bivariate(x):\n",
    "    return x[0] ** 2 + x[1] ** 2\n",
    "x0 = np.array([2, 3])\n",
    "grad = np.gradient([f_bivariate([x0[0] + h, x0[1]]) - f_bivariate(x0) for h in [-1e-6, 0, 1e-6]], 1e-6)[1]\n",
    "print(\"Gradient at (2,3):\", grad)  # Simplified, needs adjustment for true gradient\n",
    "```\n",
    "\n",
    "### Probability Basics\n",
    "\n",
    "``` python\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Probability Rules and Expectation\n",
    "p_A, p_B, p_A_and_B = 0.4, 0.3, 0.1\n",
    "print(\"P(A or B):\", p_A + p_B - p_A_and_B)\n",
    "print(\"P(A and B, independent):\", p_A * p_B)\n",
    "values = np.array([0, 1, 2])\n",
    "probs = np.array([0.5, 0.3, 0.2])\n",
    "print(\"Expectation:\", np.average(values, weights=probs))\n",
    "```\n",
    "\n",
    "### Central Limit Theorem\n",
    "\n",
    "``` python\n",
    "import numpy as np\n",
    "\n",
    "# CLT Simulation\n",
    "population = np.array([1, 2, 3, 4, 5, 6])\n",
    "sample_size, num_samples = 10, 100\n",
    "sample_means = [np.mean(np.random.choice(population, sample_size)) for _ in range(num_samples)]\n",
    "print(\"CLT Mean, Variance:\", np.mean(sample_means), np.var(sample_means, ddof=1))\n",
    "```\n",
    "\n",
    "### Sampling\n",
    "\n",
    "``` python\n",
    "import numpy as np\n",
    "\n",
    "# Random Sampling\n",
    "population = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "sample = np.random.choice(population, size=3, replace=False)\n",
    "print(\"Random Sample:\", sample)\n",
    "```\n",
    "\n",
    "### Optimization Techniques\n",
    "\n",
    "``` python\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "# Gradient Descent (Library-Based)\n",
    "def f(x):\n",
    "    return x ** 2\n",
    "result = minimize(f, x0=2)\n",
    "print(\"Optimal x for f(x)=x^2:\", result.x[0])\n",
    "```"
   ],
   "id": "42a14256-91c8-446e-92a7-ab6bf11055d3"
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {}
}
